{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3175,"databundleVersionId":44352,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft\n!pip install --upgrade peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:06:25.957122Z","iopub.execute_input":"2024-11-30T14:06:25.957686Z","iopub.status.idle":"2024-11-30T14:06:43.470542Z","shell.execute_reply.started":"2024-11-30T14:06:25.957655Z","shell.execute_reply":"2024-11-30T14:06:43.469702Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom transformers import ResNetModel, ResNetConfig\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torch import nn, optim\nimport peft\nfrom peft import get_peft_model\nfrom peft import LoraConfig\nimport torch\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:12:16.269157Z","iopub.execute_input":"2024-11-30T14:12:16.269494Z","iopub.status.idle":"2024-11-30T14:12:16.275324Z","shell.execute_reply.started":"2024-11-30T14:12:16.269464Z","shell.execute_reply":"2024-11-30T14:12:16.274493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip /kaggle/input/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:07:18.738347Z","iopub.execute_input":"2024-11-30T14:07:18.739243Z","iopub.status.idle":"2024-11-30T14:07:19.915498Z","shell.execute_reply.started":"2024-11-30T14:07:18.73919Z","shell.execute_reply":"2024-11-30T14:07:19.914649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip /kaggle/input/galaxy-zoo-the-galaxy-challenge/images_training_rev1.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip /kaggle/input/galaxy-zoo-the-galaxy-challenge/images_test_rev1.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/training_solutions_rev1.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:12:20.495365Z","iopub.execute_input":"2024-11-30T14:12:20.496053Z","iopub.status.idle":"2024-11-30T14:12:20.745529Z","shell.execute_reply.started":"2024-11-30T14:12:20.496018Z","shell.execute_reply":"2024-11-30T14:12:20.744811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:11:20.306978Z","iopub.execute_input":"2024-11-30T14:11:20.307657Z","iopub.status.idle":"2024-11-30T14:11:20.328439Z","shell.execute_reply.started":"2024-11-30T14:11:20.30762Z","shell.execute_reply":"2024-11-30T14:11:20.327482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folder_path = \"/kaggle/working/images_training_rev1\" \n\nimage_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.png', '.jpg', '.jpeg'))]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:11:28.969222Z","iopub.execute_input":"2024-11-30T14:11:28.969536Z","iopub.status.idle":"2024-11-30T14:11:29.065708Z","shell.execute_reply.started":"2024-11-30T14:11:28.969509Z","shell.execute_reply":"2024-11-30T14:11:29.065068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:11:32.278855Z","iopub.execute_input":"2024-11-30T14:11:32.279217Z","iopub.status.idle":"2024-11-30T14:11:32.284296Z","shell.execute_reply.started":"2024-11-30T14:11:32.279185Z","shell.execute_reply":"2024-11-30T14:11:32.28303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GalaxyZooDataset(Dataset):\n    def __init__(self, data, images_folder, transform=None):\n        self.data = data \n        self.images_folder = images_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        galaxy_id = str(int(row['GalaxyID']))\n        image_path = os.path.join(self.images_folder, f\"{galaxy_id}.jpg\")  \n        \n        if not os.path.exists(image_path):\n            print(f\"Image {image_path} not found.\")\n            image = Image.new('RGB', (224, 224), color=(255, 255, 255)) \n        else:\n            image = Image.open(image_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n        \n        labels = torch.tensor(row[1:].values, dtype=torch.float)\n        \n        return image, labels\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndf = pd.read_csv(\"/kaggle/working/training_solutions_rev1.csv\")\n\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)  # 80% train, 20% test\n\ntrain_dataset = GalaxyZooDataset(data=train_df, images_folder=\"/kaggle/working/images_training_rev1\", transform=transform)\ntest_dataset = GalaxyZooDataset(data=test_df, images_folder=\"/kaggle/working/images_training_rev1\", transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:12:43.598921Z","iopub.execute_input":"2024-11-30T14:12:43.599665Z","iopub.status.idle":"2024-11-30T14:12:43.86681Z","shell.execute_reply.started":"2024-11-30T14:12:43.599629Z","shell.execute_reply":"2024-11-30T14:12:43.865823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad(): \n        for images, labels in tqdm(dataloader):\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            \n            probs = F.softmax(outputs, dim=1)\n            \n            _, predicted = torch.max(probs, 1)\n\n            labels = labels.argmax(dim=1) \n\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total * 100\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:12:51.606039Z","iopub.execute_input":"2024-11-30T14:12:51.606465Z","iopub.status.idle":"2024-11-30T14:12:51.612227Z","shell.execute_reply.started":"2024-11-30T14:12:51.606432Z","shell.execute_reply":"2024-11-30T14:12:51.611271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### NORMAL FINE-TUNING","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 37)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:12:59.618815Z","iopub.execute_input":"2024-11-30T14:12:59.619631Z","iopub.status.idle":"2024-11-30T14:13:00.812487Z","shell.execute_reply.started":"2024-11-30T14:12:59.619595Z","shell.execute_reply":"2024-11-30T14:13:00.811517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = model.to(device)\nprint(\"Accuracy before finetuning is : \",evaluate_model(model,test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:13:07.306645Z","iopub.execute_input":"2024-11-30T14:13:07.307307Z","iopub.status.idle":"2024-11-30T14:14:24.208332Z","shell.execute_reply.started":"2024-11-30T14:13:07.307269Z","shell.execute_reply":"2024-11-30T14:14:24.207467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:14:44.285551Z","iopub.execute_input":"2024-11-30T14:14:44.286248Z","iopub.status.idle":"2024-11-30T14:14:44.29125Z","shell.execute_reply.started":"2024-11-30T14:14:44.286212Z","shell.execute_reply":"2024-11-30T14:14:44.290251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, num_epochs=2):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        \n        for images, labels in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f\"Loss: {running_loss / len(dataloader):.4f}\")\n\ntrain_model(model, train_loader, optimizer)\n\nfine_tuned_loss = evaluate_model(model, test_loader)\nprint(f\"Fine-tuned Model Accuracy: {fine_tuned_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:14:47.739354Z","iopub.execute_input":"2024-11-30T14:14:47.739696Z","iopub.status.idle":"2024-11-30T14:39:11.169935Z","shell.execute_reply.started":"2024-11-30T14:14:47.73967Z","shell.execute_reply":"2024-11-30T14:39:11.168954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nprint(\"Accuracy of normal fine-tuning\",evaluate_model(model,test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:39:11.171869Z","iopub.execute_input":"2024-11-30T14:39:11.172506Z","iopub.status.idle":"2024-11-30T14:40:29.315708Z","shell.execute_reply.started":"2024-11-30T14:39:11.172468Z","shell.execute_reply":"2024-11-30T14:40:29.31491Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LORA FINE-TUNING","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 37) \n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=['fc'],\n    lora_dropout=0.01,\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:40:29.316741Z","iopub.execute_input":"2024-11-30T14:40:29.317107Z","iopub.status.idle":"2024-11-30T14:40:29.859933Z","shell.execute_reply.started":"2024-11-30T14:40:29.317049Z","shell.execute_reply":"2024-11-30T14:40:29.859005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\ncriterion = nn.CrossEntropyLoss()\n\ndef train_model_with_lora(model, dataloader, optimizer, num_epochs=2):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        \n        for images, labels in tqdm(dataloader, desc=f\"LoRA Fine-tuning Epoch {epoch+1}\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            # print(outputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f\"Loss: {running_loss / len(dataloader):.4f}\")\n\ntrain_model_with_lora(model, train_loader, optimizer)\n\nlora_fine_tuned_loss = evaluate_model(model, test_loader)\nprint(f\"LoRA Fine-tuned Model Accuracy: {lora_fine_tuned_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:40:29.861795Z","iopub.execute_input":"2024-11-30T14:40:29.862803Z","iopub.status.idle":"2024-11-30T14:52:31.046833Z","shell.execute_reply.started":"2024-11-30T14:40:29.862761Z","shell.execute_reply":"2024-11-30T14:52:31.045778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nprint(\"Accuracy of lora fine-tuning\",evaluate_model(model,test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:52:31.04818Z","iopub.execute_input":"2024-11-30T14:52:31.048755Z","iopub.status.idle":"2024-11-30T14:53:49.228691Z","shell.execute_reply.started":"2024-11-30T14:52:31.048714Z","shell.execute_reply":"2024-11-30T14:53:49.227787Z"}},"outputs":[],"execution_count":null}]}